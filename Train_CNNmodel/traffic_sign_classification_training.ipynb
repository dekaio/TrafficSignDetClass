{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "#!pip install scikit-image==0.17.2 \n",
    "# !pip install imutils\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../Dataset/GTSRB_CNN\"\n",
    "save_path = \"./trafficsignnet.model\"\n",
    "plot_path = \"./plot.png\"\n",
    "test_path = \"./Test/\"\n",
    "example_path = \"./examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "class TrafficSignNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # CONV => RELU => BN => POOL\n",
    "        model.add(Conv2D(8, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        # first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "                  \n",
    "        # second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "                  \n",
    "        # first set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "                  \n",
    "        # second set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "                  \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "                  \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the dataset from the csv.\n",
    "def load(basePath, csvPath):\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    rows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
    "    #shuffling rows to shuffle classes\n",
    "    random.shuffle(rows)\n",
    "    \n",
    "    # loop over the rows\n",
    "    for (i, row) in enumerate(rows):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"[INFO] processed {} total images\".format(i))\n",
    "       \n",
    "        #split each row\n",
    "        (label, imagePath) = row.strip().split(\",\")[-2:]\n",
    "        \n",
    "        #load each path\n",
    "        imagePath = os.path.sep.join([basePath, imagePath])\n",
    "        image = cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # resize the image to be 32x32 pixels and \n",
    "        # applying Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
    "        image = transform.resize(image, (32, 32))\n",
    "        image = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
    "        data.append(image)\n",
    "        labels.append(int(label))\n",
    "        \n",
    "    # convering to np array\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading training and testing data...\n",
      "[INFO] processed 0 total images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000 total images\n",
      "[INFO] processed 2000 total images\n",
      "[INFO] processed 3000 total images\n",
      "[INFO] processed 4000 total images\n",
      "[INFO] processed 5000 total images\n",
      "[INFO] processed 6000 total images\n",
      "[INFO] processed 7000 total images\n",
      "[INFO] processed 8000 total images\n",
      "[INFO] processed 9000 total images\n",
      "[INFO] processed 10000 total images\n",
      "[INFO] processed 11000 total images\n",
      "[INFO] processed 12000 total images\n",
      "[INFO] processed 13000 total images\n",
      "[INFO] processed 14000 total images\n",
      "[INFO] processed 15000 total images\n",
      "[INFO] processed 16000 total images\n",
      "[INFO] processed 17000 total images\n",
      "[INFO] processed 18000 total images\n",
      "[INFO] processed 19000 total images\n",
      "[INFO] processed 20000 total images\n",
      "[INFO] processed 21000 total images\n",
      "[INFO] processed 22000 total images\n",
      "[INFO] processed 23000 total images\n",
      "[INFO] processed 24000 total images\n",
      "[INFO] processed 25000 total images\n",
      "[INFO] processed 26000 total images\n",
      "[INFO] processed 27000 total images\n",
      "[INFO] processed 28000 total images\n",
      "[INFO] processed 29000 total images\n",
      "[INFO] processed 30000 total images\n",
      "[INFO] processed 31000 total images\n",
      "[INFO] processed 32000 total images\n",
      "[INFO] processed 33000 total images\n",
      "[INFO] processed 34000 total images\n",
      "[INFO] processed 35000 total images\n",
      "[INFO] processed 36000 total images\n",
      "[INFO] processed 37000 total images\n",
      "[INFO] processed 38000 total images\n",
      "[INFO] processed 39000 total images\n",
      "[INFO] processed 0 total images\n",
      "[INFO] processed 1000 total images\n",
      "[INFO] processed 2000 total images\n",
      "[INFO] processed 3000 total images\n",
      "[INFO] processed 4000 total images\n",
      "[INFO] processed 5000 total images\n",
      "[INFO] processed 6000 total images\n",
      "[INFO] processed 7000 total images\n",
      "[INFO] processed 8000 total images\n",
      "[INFO] processed 9000 total images\n",
      "[INFO] processed 10000 total images\n",
      "[INFO] processed 11000 total images\n",
      "[INFO] processed 12000 total images\n"
     ]
    }
   ],
   "source": [
    "# derive training and testing CSV paths\n",
    "trainPath = os.path.sep.join([base_path, \"Train.csv\"])\n",
    "testPath = os.path.sep.join([base_path, \"Test.csv\"])\n",
    "\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading training and testing data...\")\n",
    "(trainX, trainY) = load(base_path, trainPath)\n",
    "(testX, testY) = load(base_path, testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters for training:\n",
    "NUM_EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "\n",
    "#this is an arbitary name file that was found with the dataset. \n",
    "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "# one-hot encode the training and testing labels\n",
    "numLabels = len(np.unique(trainY))\n",
    "trainY = to_categorical(trainY, numLabels)\n",
    "testY = to_categorical(testY, numLabels)\n",
    "\n",
    "#accounting for the skewed classes\n",
    "classTotals = trainY.sum(axis=0)\n",
    "classWeight = dict()\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain = trainX\n",
    "temptest = testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = trainX\n",
    "teX = testX\n",
    "# trY = trainY[:,:,:,np.newaxis]\n",
    "# trY = testX[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = np.expand_dims(trainX,3)\n",
    "teX = np.expand_dims(testX,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/30\n",
      "610/612 [============================>.] - ETA: 0s - loss: 8.0373 - accuracy: 0.1605"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:235 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 32, 32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3cbffc84cdcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassWeight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     verbose=1)\n\u001b[0m",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 764\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323 test_function  *\n        return step_function(self, iterator)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307 run_step  **\n        outputs = model.test_step(data)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266 test_step\n        y_pred = self(x, training=False)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    D:\\Soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:235 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "#data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# initialize and compiiling\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
    "model = TrafficSignNet.build(width=32, height=32, depth=1,\n",
    "        classes=numLabels)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "#early callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                            patience=5,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=trX.shape[0] // BS,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    class_weight=classWeight,\n",
    "    callbacks=[callback],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "        predictions.argmax(axis=1), target_names=labelNames))\n",
    "\n",
    "# save the network\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"[INFO] serializing network to '{}.{}'...\".format(save_path,timestr))\n",
    "# save_path = os.path.sep.join(save_path,)\n",
    "model.save(os.path.sep.join([save_path,timestr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, callback.stopped_epoch+1)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"D:\\GTSRB Dataset\\gtsrb\\\\\"\n",
    "save_path = \"./trafficsignnet.model\"\n",
    "plot_path = \"./plot.png\"\n",
    "test_path = \"./Test/\"\n",
    "example_path = \"./examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the input images and putting them into a numpy array\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 1\n",
    "classes = 43\n",
    "n_inputs = height * width*channels\n",
    "NUM_EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "\n",
    "for i in range(classes) :\n",
    "    path = base_path+\"/train/{0}/\".format(i)\n",
    "    print(path)\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a, cv2.IMREAD_GRAYSCALE)\n",
    "#             print(image)\n",
    "#             image_from_array = Image.fromarray(image, 'L')\n",
    "            image = cv2.resize(image, (height, width))\n",
    "            data.append(np.array(image))\n",
    "#             print(image)\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\"Error\")\n",
    "#     print(data)\n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "#Randomize the order of the input images\n",
    "s=np.arange(Cells.shape[0])\n",
    "np.random.seed(43)\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the images into train and validation sets\n",
    "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
    "X_train = X_train.astype('float32')/255 \n",
    "X_val = X_val.astype('float32')/255\n",
    "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n",
    "\n",
    "#Using one hote encoding for the train and validation labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accounting for the skewed classes\n",
    "classTotals = y_train.sum(axis=0)\n",
    "classWeight = dict()\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "# teX = testX[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the DNN model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# initialize and compiiling\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
    "# model = TrafficSignNet.build(width=32, height=32, depth=1,\n",
    "#         classes=numLabels)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "#early callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                            patience=5,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "history = model.fit(\n",
    "    aug.flow(X_train, y_train, batch_size=BS),\n",
    "    validation_data=(X_val, y_val),\n",
    "    steps_per_epoch=X_train.shape[0] // BS,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    class_weight=classWeight,\n",
    "    callbacks=[callback],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #using ten epochs for the training and saving the accuracy for each epoch\n",
    "# epochs = 20\n",
    "# history = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "# validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display of the accuracy and the loss values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predicting with the test data\n",
    "y_test=pd.read_csv(base_path+\"Test.csv\")\n",
    "labels=y_test['Path'].values\n",
    "y_test=y_test['ClassId'].values\n",
    "\n",
    "\n",
    "data=[]\n",
    "\n",
    "for f in labels:\n",
    "    image=cv2.imread(base_path+f, cv2.IMREAD_GRAYSCALE)\n",
    "#             image_from_array = Image.fromarray(image, 'L')\n",
    "#     print(base_path+f)\n",
    "    image = cv2.resize(image, (height, width))\n",
    "    data.append(np.array(image))\n",
    "\n",
    "testX=np.array(data)\n",
    "testX = testX.astype('float32')/255 \n",
    "pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX)\n",
    "print(classification_report(y_test,pred, target_names=labelNames))\n",
    "\n",
    "# save the network\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"[INFO] serializing network to '{}.{}'...\".format(save_path,timestr))\n",
    "# save_path = os.path.sep.join(save_path,)\n",
    "model.save(os.path.sep.join([save_path,timestr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester to load YOLO model and run detection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "from skimage import io\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot an image\n",
    "def plot_img(image, label,size=[6.4,4.8]):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.axis(False)\n",
    "    plt.title(label)\n",
    "    plt.imshow(image)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict label for each input box\n",
    "\n",
    "def predict_label(model, roi, labelNames):\n",
    "    try:\n",
    "        image = cv2.resize(roi,(32, 32))\n",
    "    except:\n",
    "        return \"0\"\n",
    "    image = image[np.newaxis,:,:,np.newaxis]\n",
    "    image = np.array(image).astype(\"float32\") / 255.0\n",
    "    \n",
    "    # make predictions\n",
    "    preds = model.predict(image)\n",
    "    print(preds)\n",
    "    print(np.max(preds))\n",
    "    if np.max(preds)>0.75:\n",
    "        j = preds.argmax(axis=1)[0]\n",
    "        label = labelNames[j]\n",
    "    else:\n",
    "        label = \"others\"\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw boxes and labels on the first input image\n",
    "\n",
    "def detected_image(image_path, bbs, labels):\n",
    "    image = io.imread(image_path)\n",
    "    for box,label in zip(bbs,labels):\n",
    "        cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[0] + box[2]), int(box[1] + box[3])), [172 , 10, 127], 2)\n",
    "        cv2.putText(image, label, (int(box[0] + box[2]), int(box[1] + box[3])), cv2.FONT_HERSHEY_DUPLEX,0.75, (255, 255, 0), 2)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to crop box\n",
    "def crop_roi(image,box):\n",
    "    h, w = image.shape[:2]\n",
    "    x_center, y_center = (box[0] * w), (box[1] * h)\n",
    "    box_width, box_height = (box[2] * w), (box[3] * h)\n",
    "    x_min, y_min = (x_center - box_width/2), (y_center - box_height/2)\n",
    "    roi = image[int(y_min):int(y_min+box_height), int(x_min):int(x_min+box_width)]\n",
    "    return roi, [x_min, y_min,box_width, box_height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D:\\GTSRB Dataset\\gtsrb\\captured_frames\\\\frame1214.jpg\"\n",
    "output_path = \"D:\\\\GTSRB Dataset\\\\gtsrb\\\\test_output\"\n",
    "model_name = \"./trafficsignnet.model\\\\20220116-111747\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "rois = []\n",
    "labels = []\n",
    "bbs=[]\n",
    "\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(model_name)\n",
    "\n",
    "#yolo setup\n",
    "net = cv2.dnn.readNet(\"yolov4-tiny_training_last_alz.weights\", \"yolov4-tiny_training.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# print(output_layers)\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "#forward pass yolo\n",
    "image = cv2.imread(image_path)\n",
    "plot_img(image, \"final\", [16,12])\n",
    "blob = cv2.dnn.blobFromImage(image, 0.004, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "#reading again since classfier performing better on skimage\n",
    "image=cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for out in outs:\n",
    "    #     print(out.shape)\n",
    "    for detection in out:\n",
    "    #         print(len(detection))\n",
    "        confidence = np.max(detection[5:])\n",
    "        \n",
    "        if confidence > confidence_threshold:\n",
    "        #             print(confidence)\n",
    "            roi, box = crop_roi(image,detection)\n",
    "            confidences.append(float(confidence))\n",
    "            rois.append(roi)\n",
    "            boxes.append(box)\n",
    "\n",
    "\n",
    "\n",
    "#adjust overlaps\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "# load the label names\n",
    "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
    "\n",
    "for i,roi in enumerate(rois):\n",
    "    if i in indexes:\n",
    "        label = predict_label(model, roi,labelNames)\n",
    "        plot_img(roi, label,[3,3])\n",
    "        labels.append(label)\n",
    "        bbs.append(boxes[i])\n",
    "        \n",
    "image = detected_image(image_path, bbs, labels)    \n",
    "plot_img(image, \"final\", [16,12])\n",
    "io.imsave(os.path.join(output_path,image_path.split(\"\\\\\")[-1]),image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"D:\\\\GTSRB Dataset\\\\gtsrb\\\\video_input\\\\munich.mp4\"\n",
    "output_path = \"D:\\\\GTSRB Dataset\\\\gtsrb\\\\video_output\"\n",
    "model_name = \"./trafficsignnet.model\\\\20220116-090355\"\n",
    "path = os.path.join(output_path,video_path.split(\"\\\\\")[-1])\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "tfps = 30\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "curr_frame = 0\n",
    "\n",
    "print (\"Set 1: \", str(round(time.time()-start_time, 2)))\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(model_name)\n",
    "print (\"Set 2: \", str(round(time.time()-start_time, 2)))\n",
    "start_time = time.time()\n",
    "\n",
    "#yolo setup\n",
    "net = cv2.dnn.readNet(\"yolov4-tiny_training_last_alz.weights\", \"yolov4-tiny_training.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# print(output_layers)\n",
    "confidence_threshold = 0.5\n",
    "print (\"Set 3: \", str(round(time.time()-start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    elif np.count_nonzero(np.array(frame.shape))<3:\n",
    "        continue\n",
    "    i+=1\n",
    "    # print (\"Set 4: \", str(round(time.time()-start_time, 2)))\n",
    "    if i%5 == 0:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            curr_frame +=1\n",
    "            image_path = 'captured_frames/frame'+str(curr_frame)+'.jpg'\n",
    "            cv2.imwrite('captured_frames/frame'+str(curr_frame)+'.jpg',frame)\n",
    "            #         img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # print (\"Set 3: \", str(round(time.time(), 2)))\n",
    "            class_ids = []\n",
    "            confidences = []\n",
    "            boxes = []\n",
    "            rois = []\n",
    "            labels = []\n",
    "            bbs=[]\n",
    "\n",
    "\n",
    "            #forward pass yolo\n",
    "            image = cv2.imread(image_path)\n",
    "            blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(output_layers)\n",
    "\n",
    "            #reading again since classfier performing better on skimage\n",
    "            image=cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    confidence = np.max(detection[5:])\n",
    "\n",
    "                    if confidence > confidence_threshold:\n",
    "                        roi, box = crop_roi(image,detection)\n",
    "                        confidences.append(float(confidence))\n",
    "                        rois.append(roi)\n",
    "                        boxes.append(box)\n",
    "\n",
    "            #adjust overlaps\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "            for i,roi in enumerate(rois):\n",
    "                if i in indexes:\n",
    "                    label = predict_label(model, roi)\n",
    "                    labels.append(label)\n",
    "                    bbs.append(boxes[i])\n",
    "\n",
    "            image = detected_image(image_path, bbs, labels)    \n",
    "            io.imsave(path+\"\\\\frame\"+str(curr_frame),image)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = 1/elapsed_time\n",
    "            print (\"frame\", curr_frame)\n",
    "            print (\"fps: \", str(round(fps, 2)))\n",
    "        except ValueError:\n",
    "            continue\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"D:\\\\GTSRB Dataset\\\\gtsrb\\\\video_input\\\\munich.mp4\"\n",
    "output_path = \"D:\\\\GTSRB Dataset\\\\gtsrb\\\\video_output\"\n",
    "model_name = \"./trafficsignnet.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(output_path,video_path.split(\"\\\\\")[-1])\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(path+\"\\\\frame\"+str(curr_frame))\n",
    "io.imsave(path+\"\\\\frame\"+str(curr_frame),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
